{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GJxBQ2q6NAB9"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPa6TxR35RQEkxistj2cRLP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flohmannjr/tensorflow_curso/blob/main/TensorFlow_MP1_Food_Vision_Big.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Milestone Project: Food Vision Big"
      ],
      "metadata": {
        "id": "UVAzWGbO5Flk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras import mixed_precision, Model, Sequential\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.layers import RandomFlip, RandomHeight, RandomRotation, RandomWidth, RandomZoom\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "PUDEEpXB8fNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "bYIefgtjOAGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [8, 5]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.style.use('seaborn-darkgrid')"
      ],
      "metadata": {
        "id": "T_u3SG7QOCXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constantes"
      ],
      "metadata": {
        "id": "HFAMby9kOGWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEMENTE = 2008193\n",
        "\n",
        "FORMATO_ENTRADA = (224, 224, 3)\n",
        "ATIVACAO = 'softmax'\n",
        "\n",
        "PERDA = 'sparse_categorical_crossentropy'\n",
        "METRICAS = ['accuracy']\n",
        "\n",
        "# OTIMIZADOR = 'Adam'\n",
        "APRENDIZADO = 0.001\n",
        "\n",
        "ITERACOES = 5"
      ],
      "metadata": {
        "id": "5q6UnPqAOJIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções "
      ],
      "metadata": {
        "id": "emz5dwYepZrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessar_imagem(imagem, rotulo, tamanho=224, escalonar=False):\n",
        "    \"\"\"\n",
        "    Redimensiona imagem para (tamanho, tamanho) e converte o dtype para float32.\n",
        "\n",
        "    Args:\n",
        "        imagem (tensor): Tensor no formato [lote, altura, largura, canais] ou [altura, largura, canais].\n",
        "        rotulo (int): Rótulo (não será processado).\n",
        "        tamanho (int): Tamanho em que a imagem será redimensionada.\n",
        "        escalonar (bool): A imagem será escalonada ou não.\n",
        "    \n",
        "    Return:\n",
        "        [lote, altura, largura, canais] ou [altura, largura, canais] (float32), rotulo\n",
        "    \"\"\"\n",
        "\n",
        "    imagem = tf.image.resize(imagem, [tamanho, tamanho])\n",
        "\n",
        "    if escalonar:\n",
        "        imagem = tf.divide(imagem, 255.)\n",
        "\n",
        "    return tf.cast(imagem, tf.float32), rotulo"
      ],
      "metadata": {
        "id": "tPVf8uSbpdDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow Dataset: Food101"
      ],
      "metadata": {
        "id": "6pIEaQzTHhz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/datasets/overview"
      ],
      "metadata": {
        "id": "wqZ1bWhFH5v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(dados_treino, dados_teste), dados_info = tfds.load(name='food101',\n",
        "                                                    split=['train', 'validation'],\n",
        "                                                    shuffle_files=True,\n",
        "                                                    as_supervised=True, # Dados em formato tuple (data, label)\n",
        "                                                    with_info=True)"
      ],
      "metadata": {
        "id": "74t8FyXcIKT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rotulos = dados_info.features['label'].names"
      ],
      "metadata": {
        "id": "icjIvXBJM3H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo"
      ],
      "metadata": {
        "id": "GJxBQ2q6NAB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exemplo = dados_treino.take(1) # Seleção aleatória\n",
        "# exemplo"
      ],
      "metadata": {
        "id": "-TNKWZQjTOEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for imagem, rotulo in exemplo:\n",
        "#     print(f\"\"\"\n",
        "#     Formato da imagem: {imagem.shape}\n",
        "#     Tipo de dado da imagem: {imagem.dtype}\n",
        "#     Alcance dos valores da imagem: {tf.reduce_min(imagem)}, {tf.reduce_max(imagem)}\n",
        "#     Formato do rótulo: {rotulo.shape}\n",
        "#     Tipo de dado do rótulo: {rotulo.dtype}\n",
        "#     Rótulo: {rotulo} ({rotulos[rotulo]})\n",
        "#     \"\"\")\n",
        "\n",
        "# plt.imshow(imagem)\n",
        "# plt.title(rotulos[rotulo])\n",
        "# plt.axis(False);"
      ],
      "metadata": {
        "id": "y4VrtfmXTbwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparar e lotear datasets"
      ],
      "metadata": {
        "id": "7xrVdyx1W4NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/guide/data_performance\n",
        "\n",
        "**Best practice summary**\n",
        "\n",
        "Here is a summary of the best practices for designing performant TensorFlow input pipelines:\n",
        "\n",
        "* **Use the `prefetch` transformation** to overlap the work of a producer and consumer\n",
        "* **Parallelize the data reading transformation** using the `interleave` transformation\n",
        "* **Parallelize the `map` transformation** by setting the `num_parallel_calls` argument\n",
        "* **Use the `cache` transformation** to cache data in memory during the first epoch\n",
        "* **Vectorize user-defined functions** passed in to the `map` transformation\n",
        "* **Reduce memory usage** when applying the `interleave`, `prefetch`, and `shuffle` transformations"
      ],
      "metadata": {
        "id": "GkPXeizOYyUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapear dados de treino (função de pré-processamento e paralelização).\n",
        "dados_treino = dados_treino.map(map_func=preprocessar_imagem, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Embaralhar dados de treino.\n",
        "dados_treino = dados_treino.shuffle(buffer_size=1000)\n",
        "\n",
        "# Lotear e pré-buscar dados de treino.\n",
        "dados_treino = dados_treino.batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Mapear, lotear e pré-bucar dados de teste.\n",
        "dados_teste = dados_teste.map(map_func=preprocessar_imagem, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "dados_treino, dados_teste"
      ],
      "metadata": {
        "id": "GV45xHKIb167"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precisão mista"
      ],
      "metadata": {
        "id": "qmmMzI7eraeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/guide/mixed_precision"
      ],
      "metadata": {
        "id": "pbMId3TWvuWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bugado para EfficientNetBX em TensorFlow 2.5+\n",
        "# `x` and `y` must have the same dtype, got tf.float16 != tf.float32.\n",
        "\n",
        "# mixed_precision.set_global_policy(\"mixed_float16\")"
      ],
      "metadata": {
        "id": "tWs_HqjiwnNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo"
      ],
      "metadata": {
        "id": "chV7AX5BxCMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_base = EfficientNetB0(include_top=False)\n",
        "modelo_base.trainable = False\n",
        "\n",
        "entradas = Input(shape=FORMATO_ENTRADA, name='camada_entrada')\n",
        "\n",
        "expansao_dados = Sequential(name='expansao_dados')\n",
        "\n",
        "expansao_dados.add(RandomFlip('horizontal'))\n",
        "expansao_dados.add(RandomHeight(0.2))\n",
        "expansao_dados.add(RandomRotation(0.2))\n",
        "expansao_dados.add(RandomWidth(0.2))\n",
        "expansao_dados.add(RandomZoom(0.2))\n",
        "\n",
        "# Há um bug na versão 2.8 do TensorFlow que faz necessário forçar o treinamento para que a expansão dos dados funcione.\n",
        "expandidos = expansao_dados(entradas, training=True)\n",
        "\n",
        "camadas = modelo_base(expandidos, training=False)\n",
        "camadas = GlobalAveragePooling2D(name='agrupamento_media_global')(camadas)\n",
        "\n",
        "saidas = Dense(len(rotulos), activation=ATIVACAO, name='camada_saida')(camadas)\n",
        "\n",
        "modelo = Model(inputs=entradas, outputs=saidas)\n",
        "\n",
        "modelo.compile(loss=PERDA,\n",
        "               optimizer=Adam(learning_rate=APRENDIZADO),\n",
        "               metrics=METRICAS)"
      ],
      "metadata": {
        "id": "c0BztZf3xDtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificar uso de precisão mista"
      ],
      "metadata": {
        "id": "rFnqDrPKzS5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for camada in modelo.layers:\n",
        "#     print(camada.name, camada.trainable, camada.dtype, camada.dtype_policy)"
      ],
      "metadata": {
        "id": "igUfmYlJ0KQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ajustar"
      ],
      "metadata": {
        "id": "seXvE6xw0uh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historico = modelo.fit(dados_treino,\n",
        "                       epochs=ITERACOES,\n",
        "                       steps_per_epoch=len(dados_treino),\n",
        "                    #    validation_data=dados_teste,\n",
        "                    #    validation_steps=len(dados_teste),\n",
        "                       verbose=1)"
      ],
      "metadata": {
        "id": "TSR4DK410v9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliar"
      ],
      "metadata": {
        "id": "Cccb7XYl1RK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.evaluate(dados_teste)"
      ],
      "metadata": {
        "id": "mcO2V1BU1Txd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_verdadeiras = []\n",
        "\n",
        "for imagem, classe in dados_teste.unbatch():\n",
        "    classes_verdadeiras.append(classe.numpy().argmax())\n",
        "\n",
        "previsoes = modelo.predict(dados_teste, verbose=1)\n",
        "\n",
        "classes_previstas = previsoes.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_true=classes_verdadeiras,\n",
        "                            y_pred=classes_previstas,\n",
        "                            target_names=rotulos))"
      ],
      "metadata": {
        "id": "fAvgfG7g1Ydp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EqdR1PbW2V0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}