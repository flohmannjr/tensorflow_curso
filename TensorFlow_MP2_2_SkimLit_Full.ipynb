{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7Il7fRUBOjckMaatAb4i8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flohmannjr/tensorflow_curso/blob/main/TensorFlow_MP2_2_SkimLit_Full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Milestone Project 2.2: SkimLit Full"
      ],
      "metadata": {
        "id": "ym_83ON7bfRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é a continuidade do projeto SkimLit+.\n",
        "\n",
        "Neste projeto a base de dados PubMed 200k RCT completa é utilizada.\n",
        "\n",
        "* `pubmed-rct/PubMed_200k_RCT/train.txt`\n",
        "* `pubmed-rct/PubMed_200k_RCT/test.txt`"
      ],
      "metadata": {
        "id": "HE2o9-n-Uqpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importações"
      ],
      "metadata": {
        "id": "ZRx1Qbr9bQ85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.data import AUTOTUNE, Dataset\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Dense, Dropout, Embedding, Input, LSTM, TextVectorization\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "metadata": {
        "id": "WJhI_c3LVUw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurações e constantes"
      ],
      "metadata": {
        "id": "4rMYPNLEVUuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [8, 5]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "\n",
        "COR = '#007f66'\n",
        "\n",
        "DIRETORIO = '/content/pubmed-rct/PubMed_200k_RCT'\n",
        "\n",
        "LIMITE_DICIONARIO = 331000\n",
        "LIMITE_CARACTERES = 80\n",
        "\n",
        "LIMITE_INCORPORADOR = 300\n",
        "LIMITE_INCORPORADOR_CARACTERES = 25\n",
        "LIMITE_VETOR_TEXTO = 100\n",
        "\n",
        "LOTE_TAMANHO = 32\n",
        "\n",
        "ENTRADA_FORMATO = (1,)\n",
        "ENTRADA_TIPO = tf.string\n",
        "\n",
        "ATIVACAO_CNN = 'relu'\n",
        "ATIVACAO_RNN = 'tanh'\n",
        "ATIVACAO_SAIDA = 'softmax'\n",
        "\n",
        "SUAVIZACAO = 0.2\n",
        "APRENDIZADO = 0.001\n",
        "METRICAS = ['accuracy']\n",
        "\n",
        "ITERACOES = 3"
      ],
      "metadata": {
        "id": "q2vvRySpVUrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções"
      ],
      "metadata": {
        "id": "4rM95o2VYW9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/flohmannjr/tensorflow_curso/main/funcoes.py"
      ],
      "metadata": {
        "id": "e0s3fvYaYZvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from funcoes import avaliar_modelo, grafico_historico_por_iteracao, preprocessar_texto"
      ],
      "metadata": {
        "id": "4Uc-_QZxYeHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dados"
      ],
      "metadata": {
        "id": "VaNG5j60VUlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "\n",
        "!7z e -o$DIRETORIO $DIRETORIO/train.7z"
      ],
      "metadata": {
        "id": "jXI5bG6UVQkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino = pd.DataFrame(preprocessar_texto(f'{DIRETORIO}/train.txt'))\n",
        "df_teste  = pd.DataFrame(preprocessar_texto(f'{DIRETORIO}/test.txt'))\n",
        "\n",
        "codificador_onehot = OneHotEncoder(sparse=False)\n",
        "\n",
        "rotulos_onehot_treino = codificador_onehot.fit_transform(df_treino['classe'].to_numpy().reshape(-1, 1))\n",
        "rotulos_onehot_teste  = codificador_onehot.transform(df_teste['classe'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "codificador_int = LabelEncoder()\n",
        "\n",
        "rotulos_int_treino = codificador_int.fit_transform(df_treino['classe'].to_numpy())\n",
        "rotulos_int_teste  = codificador_int.transform(df_teste['classe'].to_numpy())\n",
        "\n",
        "classes = codificador_int.classes_\n",
        "\n",
        "palavras_por_texto_98   = int(np.percentile([len(texto.split()) for texto in df_treino['texto']], 98))\n",
        "caracteres_por_texto_98 = int(np.percentile([len(texto) for texto in df_treino['texto']], 98))\n",
        "\n",
        "lista_caracteres_treino = [\" \".join(list(texto)) for texto in df_treino['texto']]\n",
        "lista_caracteres_teste  = [\" \".join(list(texto)) for texto in df_teste['texto']]\n",
        "\n",
        "numero_linha_98 = int(np.percentile(df_treino['numero'], 98))\n",
        "\n",
        "linhas_numero_onehot_treino = tf.one_hot(df_treino['numero'], depth=numero_linha_98)\n",
        "linhas_numero_onehot_teste  = tf.one_hot(df_teste['numero'], depth=numero_linha_98)\n",
        "\n",
        "total_linhas_98 = int(np.percentile(df_treino['total'], 98))\n",
        "\n",
        "linhas_total_onehot_treino = tf.one_hot(df_treino['total'], depth=total_linhas_98)\n",
        "linhas_total_onehot_teste  = tf.one_hot(df_teste['total'], depth=total_linhas_98)\n",
        "\n",
        "dados_hibridos_linhas_treino_textos  = Dataset.from_tensor_slices((df_treino['texto'], lista_caracteres_treino, linhas_numero_onehot_treino, linhas_total_onehot_treino))\n",
        "dados_hibridos_linhas_treino_rotulos = Dataset.from_tensor_slices(rotulos_onehot_treino)\n",
        "dados_hibridos_linhas_treino         = Dataset.zip((dados_hibridos_linhas_treino_textos, dados_hibridos_linhas_treino_rotulos))\n",
        "dados_hibridos_linhas_treino         = dados_hibridos_linhas_treino.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)\n",
        "\n",
        "dados_hibridos_linhas_teste_textos  = Dataset.from_tensor_slices((df_teste['texto'], lista_caracteres_teste, linhas_numero_onehot_teste, linhas_total_onehot_teste))\n",
        "dados_hibridos_linhas_teste_rotulos = Dataset.from_tensor_slices(rotulos_onehot_teste)\n",
        "dados_hibridos_linhas_teste         = Dataset.zip((dados_hibridos_linhas_teste_textos, dados_hibridos_linhas_teste_rotulos))\n",
        "dados_hibridos_linhas_teste         = dados_hibridos_linhas_teste.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "e-NI2TH_cx2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Camadas auxiliares"
      ],
      "metadata": {
        "id": "OeCPbTT6ahqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vetorizador_palavras = TextVectorization(max_tokens=LIMITE_DICIONARIO,\n",
        "                                         output_mode='int',\n",
        "                                         output_sequence_length=palavras_por_texto_98,\n",
        "                                         name='vetorizador_palavras')\n",
        "\n",
        "vetorizador_palavras.adapt(df_treino['texto'])\n",
        "\n",
        "vocabulario_palavras = vetorizador_palavras.get_vocabulary()\n",
        "\n",
        "incorporador_palavras = Embedding(input_dim=len(vocabulario_palavras),\n",
        "                                  output_dim=LIMITE_INCORPORADOR,\n",
        "                                  mask_zero=True,\n",
        "                                  input_length=palavras_por_texto_98,\n",
        "                                  name='incorporador_palavras')\n",
        "\n",
        "vetorizador_caracteres = TextVectorization(max_tokens=LIMITE_CARACTERES,\n",
        "                                           output_mode='int',\n",
        "                                           output_sequence_length=caracteres_por_texto_98,\n",
        "                                           name='vetorizador_caracteres')\n",
        "\n",
        "vetorizador_caracteres.adapt(lista_caracteres_treino)\n",
        "\n",
        "vocabulario_caracteres = vetorizador_caracteres.get_vocabulary()\n",
        "\n",
        "incorporador_caracteres = Embedding(input_dim=len(vocabulario_caracteres),\n",
        "                                    output_dim=LIMITE_INCORPORADOR_CARACTERES,\n",
        "                                    mask_zero=True,\n",
        "                                    input_length=caracteres_por_texto_98,\n",
        "                                    name='incorporador_caracteres')"
      ],
      "metadata": {
        "id": "4lQt4RkDxpsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "DKr8Iu7E3VJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_nome = 'modelo_incorporacao_palavras'\n",
        "\n",
        "\n",
        "entradas = Input(shape=ENTRADA_FORMATO, dtype=ENTRADA_TIPO, name='camada_entrada_palavras')\n",
        "\n",
        "camadas = vetorizador_palavras(entradas)\n",
        "camadas = incorporador_palavras(camadas)\n",
        "\n",
        "saidas = Bidirectional(layer=LSTM(units=int(LIMITE_INCORPORADOR / 2), activation=ATIVACAO_RNN), name='camada_bi_lstm_palavras')(camadas)\n",
        "\n",
        "modelo_incorporacao_palavras = Model(inputs=entradas, outputs=saidas, name=modelo_nome)\n",
        "\n",
        "\n",
        "modelo_nome = 'modelo_incorporacao_caracteres'\n",
        "\n",
        "entradas = Input(shape=ENTRADA_FORMATO, dtype=ENTRADA_TIPO, name='camada_entrada_caracteres')\n",
        "\n",
        "camadas = vetorizador_caracteres(entradas)\n",
        "camadas = incorporador_caracteres(camadas)\n",
        "\n",
        "saidas = Bidirectional(layer=LSTM(units=LIMITE_INCORPORADOR_CARACTERES, activation=ATIVACAO_RNN), name='camada_bi_lstm_caracteres')(camadas)\n",
        "\n",
        "modelo_incorporacao_caracteres = Model(inputs=entradas, outputs=saidas, name=modelo_nome)\n",
        "\n",
        "\n",
        "combinacao_incorporacao = Concatenate(name=\"camada_combinacao_incorporacao\")([modelo_incorporacao_palavras.output,\n",
        "                                                                              modelo_incorporacao_caracteres.output])\n",
        "\n",
        "abandonos_incorporacao = Dense(LIMITE_VETOR_TEXTO * 2, activation=ATIVACAO_CNN, name='camada_abandonos_incorporacao_relu')(combinacao_incorporacao)\n",
        "abandonos_incorporacao = Dropout(rate=0.5, name='camada_abandonos_incorporacao')(abandonos_incorporacao)\n",
        "\n",
        "\n",
        "modelo_nome = 'modelo_numero_linhas'\n",
        "\n",
        "entradas = Input(shape=(numero_linha_98,), dtype=linhas_numero_onehot_treino.dtype, name='camada_entrada_numero_linhas')\n",
        "\n",
        "saidas = Dense(numero_linha_98 * 2, activation=ATIVACAO_CNN, name='camada_relu_numero_linhas')(entradas)\n",
        "\n",
        "modelo_numero_linhas = Model(inputs=entradas, outputs=saidas, name=modelo_nome)\n",
        "\n",
        "\n",
        "modelo_nome = 'modelo_total_linhas'\n",
        "\n",
        "entradas = Input(shape=(total_linhas_98,), dtype=linhas_total_onehot_treino.dtype, name='camada_entrada_total_linhas')\n",
        "\n",
        "saidas = Dense(total_linhas_98 * 2, activation=ATIVACAO_CNN, name='camada_relu_total_linhas')(entradas)\n",
        "\n",
        "modelo_total_linhas = Model(inputs=entradas, outputs=saidas, name=modelo_nome)\n",
        "\n",
        "\n",
        "combinacao_linhas = Concatenate(name=\"camada_combinacao_linhas\")([abandonos_incorporacao,\n",
        "                                                                  modelo_numero_linhas.output,\n",
        "                                                                  modelo_total_linhas.output])\n",
        "\n",
        "abandonos_linhas = Dense(LIMITE_VETOR_TEXTO * 2, activation=ATIVACAO_CNN, name='camada_abandonos_linhas_relu')(combinacao_linhas)\n",
        "abandonos_linhas = Dropout(rate=0.5, name='camada_abandonos_linhas')(abandonos_linhas)\n",
        "\n",
        "saidas = Dense(len(classes), activation=ATIVACAO_SAIDA, name='camada_saida')(abandonos_linhas)\n",
        "\n",
        "\n",
        "modelo_nome = 'modelo_pubmed_200k_rct'\n",
        "\n",
        "modelo = Model(inputs=[modelo_incorporacao_palavras.input,\n",
        "                       modelo_incorporacao_caracteres.input,\n",
        "                       modelo_numero_linhas.input,\n",
        "                       modelo_total_linhas.input],\n",
        "               outputs=saidas,\n",
        "               name=modelo_nome)\n",
        "\n",
        "modelo.compile(loss=CategoricalCrossentropy(label_smoothing=SUAVIZACAO),\n",
        "               optimizer=SGD(learning_rate=APRENDIZADO),\n",
        "               metrics=METRICAS)"
      ],
      "metadata": {
        "id": "cJMSjOyD5dw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificação do modelo"
      ],
      "metadata": {
        "id": "r0MZ7eJs5dw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.summary()"
      ],
      "metadata": {
        "id": "dkOKYjq35dw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(modelo, show_shapes=True)"
      ],
      "metadata": {
        "id": "8RhM3yIH5dw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finalização do modelo"
      ],
      "metadata": {
        "id": "jkVqoeAR5dw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historico = modelo.fit(dados_hibridos_linhas_treino,\n",
        "                       epochs=ITERACOES,\n",
        "                       validation_data=dados_hibridos_linhas_teste,\n",
        "                       verbose=1)"
      ],
      "metadata": {
        "id": "M4JrzThf5dw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafico_historico_por_iteracao(historico)"
      ],
      "metadata": {
        "id": "5QDx1Ngv5dw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades = modelo.predict(dados_hibridos_linhas_teste)\n",
        "previsoes      = tf.argmax(probabilidades, axis=1)\n",
        "avaliacoes     = pd.DataFrame(avaliar_modelo(rotulos_int_teste, previsoes, classes))"
      ],
      "metadata": {
        "id": "hxmcYmA45dw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes"
      ],
      "metadata": {
        "id": "jHGwpNw35dw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwGnu_VB3hSV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}