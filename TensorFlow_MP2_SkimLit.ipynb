{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPriSC75BCiPhMq4xLiRYeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flohmannjr/tensorflow_curso/blob/main/TensorFlow_MP2_SkimLit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Milestone Project: SkimLit"
      ],
      "metadata": {
        "id": "G-cwRZOT6Vee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este projeto tem como objetivo reproduzir o artigo **PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts**. https://arxiv.org/abs/1710.06071\n",
        "\n",
        "O resumo de artigos científicos de Medicina costumam ser blocos de texto de difícil interpretação imediata. Este artigo teve como propósito criar um modelo para classificação sequencial de sentenças, onde, uma vez apresentado um resumo, dividirá o texto em cinco categorias: Background, Conclusions, Methods, Objective e Results (Contexto, Conclusões, Métodos, Objetivo e Resultados), facilitando sua interpretação.\n",
        "\n",
        "PubMed 200k RCT utiliza a arquitetura do modelo do artigo **Neural Networks for Joint Sentence Classification in Medical Paper Abstracts**. https://arxiv.org/abs/1612.05251"
      ],
      "metadata": {
        "id": "X3g3-RzJsuU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import random, re\n",
        "\n",
        "from tensorflow.data import AUTOTUNE, Dataset\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, TextVectorization\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D, GlobalMaxPool1D, Input\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "metadata": {
        "id": "ND6yUaUk6kOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "bYIefgtjOAGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [8, 5]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# plt.style.use('seaborn-darkgrid')\n",
        "sns.set_style('darkgrid')"
      ],
      "metadata": {
        "id": "T_u3SG7QOCXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constantes"
      ],
      "metadata": {
        "id": "Uy_Tv0JkpVxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEMENTE = 2008193\n",
        "\n",
        "COR = '#007f66'\n",
        "\n",
        "DIRETORIO = '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign'\n",
        "# DIRETORIO = '/content/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign'\n",
        "\n",
        "# PubMed 200k RCT - Table 2\n",
        "LIMITE_DICIONARIO = 68000\n",
        "# LIMITE_DICIONARIO = 331000\n",
        "\n",
        "LIMITE_CARACTERES = 100\n",
        "\n",
        "# Neural Networks for Joint Sentence Classification - Figure 1\n",
        "LIMITE_INCORPORADOR = 300\n",
        "LIMITE_INCORPORADOR_CARACTERES = 25\n",
        "\n",
        "LOTE_TAMANHO = 32\n",
        "\n",
        "ENTRADA_FORMATO = (1,)\n",
        "ENTRADA_TIPO = tf.string\n",
        "\n",
        "ATIVACAO = 'relu'\n",
        "ATIVACAO_SAIDA = 'softmax'\n",
        "\n",
        "FILTROS = 64\n",
        "NUCLEO_TAMANHO = 5\n",
        "PREENCHIMENTO = 'same'\n",
        "\n",
        "PERDA = 'categorical_crossentropy'\n",
        "APRENDIZADO = 0.001\n",
        "METRICAS = ['accuracy']\n",
        "\n",
        "ITERACOES = 3"
      ],
      "metadata": {
        "id": "Z-1CGl0S2DiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções"
      ],
      "metadata": {
        "id": "nVZAWLhD1mhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/flohmannjr/tensorflow_curso/main/funcoes.py"
      ],
      "metadata": {
        "id": "FYXVOXEYBFVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from funcoes import avaliar_modelo, grafico_historico_por_iteracao"
      ],
      "metadata": {
        "id": "mGECR6zZBKnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessar_texto(arquivo):\n",
        "    \"\"\"\n",
        "    Retorna uma lista de dicionários com o conteúdo das linhas do arquivo informado.\n",
        "\n",
        "    Cada dicionário contém o código do resumo, o total de linhas, o número, a classe e o texto da linha.\n",
        "    {codigo, total, numero, classe, texto}\n",
        "    \"\"\"\n",
        "\n",
        "    with open(arquivo, 'r') as a: linhas_arquivo = a.readlines()\n",
        "    linhas = ''  # Linhas do texto\n",
        "    saida = []   # Lista de dicionários\n",
        "\n",
        "    for linha in linhas_arquivo:\n",
        "        if linha.startswith('###'):            # Verifica se a linha inicia com '###'.\n",
        "            codigo = re.sub('\\D+', '', linha)  # Extrai o código do resumo.\n",
        "            linhas = ''                        # Limpa as linhas de texto.\n",
        "        \n",
        "        elif linha.isspace():                       # Verifica se a linha é vazia.\n",
        "            linhas_separadas = linhas.splitlines()  # Separa linhas de texto.\n",
        "\n",
        "            for linha_numero, linha_completa in enumerate(linhas_separadas):  # Itera sobre cada uma das linhas de texto.\n",
        "                linha_dados = {}                                              # Dicionário com os dados da linha.\n",
        "                linha_conteudo = linha_completa.split('\\t')                   # Separa classe e texto.\n",
        "\n",
        "                linha_dados['codigo'] = codigo                    # Código do resumo.\n",
        "                linha_dados['total'] = len(linhas_separadas)      # Total de linhas.\n",
        "                linha_dados['numero'] = linha_numero              # Número da linha.\n",
        "                linha_dados['classe'] = linha_conteudo[0]         # Classe da linha.\n",
        "                linha_dados['texto'] = linha_conteudo[1].lower()  # Texto da linha, em caixa baixa.\n",
        "\n",
        "                saida.append(linha_dados)  # Acrescenta o dicionário à lista.\n",
        "\n",
        "        else:\n",
        "            linhas += linha  # Acrescenta a linha atual às linhas de texto.\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "Fc3LGM4_1peB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dados"
      ],
      "metadata": {
        "id": "nLfeMWwru_9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git"
      ],
      "metadata": {
        "id": "HSS_zH7py6b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pré-processamento"
      ],
      "metadata": {
        "id": "4rHNd8yc1a2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linhas_treino    = preprocessar_texto(f'{DIRETORIO}/train.txt')  # Dados de treino\n",
        "linhas_validacao = preprocessar_texto(f'{DIRETORIO}/dev.txt')    # Dados de validação\n",
        "linhas_teste     = preprocessar_texto(f'{DIRETORIO}/test.txt')   # Dados de teste"
      ],
      "metadata": {
        "id": "vZHFSSiv3MMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino    = pd.DataFrame(linhas_treino)\n",
        "df_validacao = pd.DataFrame(linhas_validacao)\n",
        "df_teste     = pd.DataFrame(linhas_teste)"
      ],
      "metadata": {
        "id": "03f210ZBYHDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificação"
      ],
      "metadata": {
        "id": "gRV03ysP1iH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino[:12]"
      ],
      "metadata": {
        "id": "4KkIE_9xZ-ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino['classe'].value_counts()"
      ],
      "metadata": {
        "id": "DxCyKmEoaM7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=df_treino, x='total', color=COR)\n",
        "\n",
        "plt.xlabel('Quantidade de linhas')\n",
        "plt.ylabel('Quantidade de resumos');"
      ],
      "metadata": {
        "id": "A56YZP5EcOA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rótulos numéricos"
      ],
      "metadata": {
        "id": "SaAEt9KddM8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-hot"
      ],
      "metadata": {
        "id": "KrqrdjCW4XFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codificador_onehot = OneHotEncoder(sparse=False)\n",
        "\n",
        "rotulos_onehot_treino    = codificador_onehot.fit_transform(df_treino['classe'].to_numpy().reshape(-1, 1))\n",
        "rotulos_onehot_validacao = codificador_onehot.transform(df_validacao['classe'].to_numpy().reshape(-1, 1))\n",
        "rotulos_onehot_teste     = codificador_onehot.transform(df_teste['classe'].to_numpy().reshape(-1, 1))"
      ],
      "metadata": {
        "id": "j2mOlwRr1pr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rotulos_onehot_treino"
      ],
      "metadata": {
        "id": "zVisvpjt2vAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inteiros"
      ],
      "metadata": {
        "id": "mw90LPah2-83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codificador_int = LabelEncoder()\n",
        "\n",
        "rotulos_int_treino    = codificador_int.fit_transform(df_treino['classe'].to_numpy())\n",
        "rotulos_int_validacao = codificador_int.transform(df_validacao['classe'].to_numpy())\n",
        "rotulos_int_teste     = codificador_int.transform(df_teste['classe'].to_numpy())"
      ],
      "metadata": {
        "id": "OsmgVFMn4iFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rotulos_int_treino"
      ],
      "metadata": {
        "id": "KKPkj4XE4iFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = codificador_int.classes_\n",
        "classes"
      ],
      "metadata": {
        "id": "gH7wCQLS46lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos"
      ],
      "metadata": {
        "id": "sF-Hny925HTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes = [None] * 6"
      ],
      "metadata": {
        "id": "O7BwmdBR7R5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo 0: TF-IDF Naive-Bayes"
      ],
      "metadata": {
        "id": "UX62Fknz7GgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_nome = 'modelo_0_tfidf_naive_bayes'\n",
        "\n",
        "modelo = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                   ('clf', MultinomialNB())])\n",
        "\n",
        "modelo.fit(df_treino['texto'], rotulos_int_treino)"
      ],
      "metadata": {
        "id": "Hb0thwq57OEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades = modelo.predict(df_validacao['texto'])"
      ],
      "metadata": {
        "id": "t9Eb1OST-YYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = np.zeros((probabilidades.size, probabilidades.max() + 1))\n",
        "previsoes[np.arange(probabilidades.size), probabilidades] = 1"
      ],
      "metadata": {
        "id": "YWeMPo_lCMbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes[0] = avaliar_modelo(rotulos_int_validacao, probabilidades, classes)"
      ],
      "metadata": {
        "id": "AmCdCp_K-2OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes[0]"
      ],
      "metadata": {
        "id": "Fjjg8COn-89_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos textos"
      ],
      "metadata": {
        "id": "VRtW8n1x-PDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palavras_por_texto    = [len(texto.split()) for texto in df_treino['texto']]\n",
        "palavras_por_texto_95 = int(np.percentile(palavras_por_texto, 95))  # Quantidade máxima de palavras para 95% dos textos."
      ],
      "metadata": {
        "id": "GWkiCt7ah6Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Média: {np.mean(palavras_por_texto)}\")\n",
        "print(f\"Máximo: {np.max(palavras_por_texto)}\")\n",
        "print(f\"95%: {palavras_por_texto_95}\")"
      ],
      "metadata": {
        "id": "ge1jUxe_iX4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(x=palavras_por_texto, color=COR)\n",
        "\n",
        "plt.xlim(0, 60)\n",
        "\n",
        "plt.xlabel('Quantidade de palavras')\n",
        "plt.ylabel('Quantidade de textos');"
      ],
      "metadata": {
        "id": "O5Vyt98piT5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vetorização"
      ],
      "metadata": {
        "id": "oZvbMm1Doyqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vetorizador = TextVectorization(max_tokens=LIMITE_DICIONARIO,\n",
        "                                output_mode='int',\n",
        "                                output_sequence_length=palavras_por_texto_95,\n",
        "                                name='vetorizador')\n",
        "\n",
        "vetorizador.adapt(df_treino['texto'])"
      ],
      "metadata": {
        "id": "KeLhjzAYH3jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vetorizador.get_config()"
      ],
      "metadata": {
        "id": "6nHcUj06QgTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vocabulário"
      ],
      "metadata": {
        "id": "VRtmy8e7YrHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario = vetorizador.get_vocabulary()\n",
        "\n",
        "print(f\"Tamanho do vocabulário: {len(vocabulario)}\")\n",
        "print(f\"10 palavras mais comuns: {vocabulario[:10]}\")\n",
        "print(f\"10 palavras menos comuns: {vocabulario[-10:]}\")"
      ],
      "metadata": {
        "id": "u10YwRExLW33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Incorporação"
      ],
      "metadata": {
        "id": "3kBsMF6VLosd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incorporador = Embedding(input_dim=len(vocabulario),\n",
        "                         output_dim=LIMITE_INCORPORADOR,\n",
        "                         mask_zero=True,\n",
        "                         input_length=palavras_por_texto_95,\n",
        "                         name='incorporador')"
      ],
      "metadata": {
        "id": "z7XbDbl1LtUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`mask_zero=True` otimiza o tratamento de preenchimento com valor zero nas camadas subsequentes e na função de perda.\n",
        "\n",
        "Mais informações: https://stackoverflow.com/questions/47485216/how-does-mask-zero-in-keras-embedding-layer-work"
      ],
      "metadata": {
        "id": "YNf0XZ4GhcsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incorporador.get_config()"
      ],
      "metadata": {
        "id": "MUKf0O-aUHub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verificação"
      ],
      "metadata": {
        "id": "XfgZ6wGIV60K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_aleatorio = random.choice(df_treino['texto'])\n",
        "\n",
        "vetorizado = vetorizador([texto_aleatorio])\n",
        "incorporado = incorporador(vetorizado)\n",
        "\n",
        "print(texto_aleatorio)\n",
        "print()\n",
        "print(f\"Quantidade de palavras: {len(texto_aleatorio.split())}\")\n",
        "print(f\"Formato vetorizado: {vetorizado.shape}\")\n",
        "print(f\"Formato incorporado: {incorporado.shape}\")\n",
        "print()\n",
        "print(vetorizado)\n",
        "print()\n",
        "print(incorporado)"
      ],
      "metadata": {
        "id": "eqhJBzTELByS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Criação de datasets"
      ],
      "metadata": {
        "id": "YA2mPLtdSzmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fusão dos dados e rótulos em datasets para ganho de performance.\n",
        "\n",
        "Better performance with the tf.data API: https://www.tensorflow.org/guide/data_performance"
      ],
      "metadata": {
        "id": "zyXYoLr-ja4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "dados_treino    = Dataset.from_tensor_slices((df_treino['texto'], rotulos_onehot_treino))\n",
        "dados_validacao = Dataset.from_tensor_slices((df_validacao['texto'], rotulos_onehot_validacao))\n",
        "dados_teste     = Dataset.from_tensor_slices((df_teste['texto'], rotulos_onehot_teste))"
      ],
      "metadata": {
        "id": "N4DJJZbJj3Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_treino"
      ],
      "metadata": {
        "id": "aHup0yT6moG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-buscas\n",
        "dados_treino    = dados_treino.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)\n",
        "dados_validacao = dados_validacao.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)\n",
        "dados_teste     = dados_teste.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "dXfcMje8mpcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_treino"
      ],
      "metadata": {
        "id": "cldjvm9YmpOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo 1: Conv1D com incorporação de palavras"
      ],
      "metadata": {
        "id": "VzH5qYgYmozK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_nome = 'modelo_1_conv1d_inc_palavras'\n",
        "\n",
        "entradas = Input(shape=ENTRADA_FORMATO, dtype=ENTRADA_TIPO, name='camada_entrada')\n",
        "\n",
        "camadas = vetorizador(entradas)\n",
        "camadas = incorporador(camadas)\n",
        "\n",
        "camadas = Conv1D(filters=FILTROS,\n",
        "                 kernel_size=NUCLEO_TAMANHO,\n",
        "                 activation=ATIVACAO,\n",
        "                 padding=PREENCHIMENTO,\n",
        "                 name='camada_convulacional')(camadas)\n",
        "\n",
        "camadas = GlobalAveragePooling1D(name='agrupamento_media_global')(camadas)\n",
        "\n",
        "saidas = Dense(len(classes), activation=ATIVACAO_SAIDA, name='camada_saida')(camadas)\n",
        "\n",
        "modelo = Model(inputs=entradas, outputs=saidas, name=modelo_nome)\n",
        "\n",
        "modelo.compile(loss=PERDA,\n",
        "               optimizer=Adam(learning_rate=APRENDIZADO),\n",
        "               metrics=METRICAS)\n",
        "\n",
        "historico = modelo.fit(dados_treino,\n",
        "                       epochs=ITERACOES,\n",
        "                       validation_data=dados_validacao,\n",
        "                       verbose=1)"
      ],
      "metadata": {
        "id": "tGq3c7yNRiq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafico_historico_por_iteracao(historico)"
      ],
      "metadata": {
        "id": "DvgTDDqKWfrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades = modelo.predict(dados_validacao)\n",
        "previsoes      = tf.argmax(probabilidades, axis=1)\n",
        "avaliacoes[1]  = avaliar_modelo(rotulos_int_validacao, previsoes, classes)"
      ],
      "metadata": {
        "id": "pESc6xprWmui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes[1]"
      ],
      "metadata": {
        "id": "P7WWed99Ytdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo 2: TFHub USE"
      ],
      "metadata": {
        "id": "LZ4fqAxTZGOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_nome = 'modelo_2_use'\n",
        "\n",
        "entradas = Input(shape=[], dtype=ENTRADA_TIPO, name='camada_entrada')  # shape=[] para entradas de tamanho variável\n",
        "\n",
        "camadas = hub.KerasLayer(handle='https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "                         trainable=False,\n",
        "                         name='camada_use')(entradas)\n",
        "\n",
        "camadas = Dense(LIMITE_INCORPORADOR, activation=ATIVACAO, name='camada_relu')(camadas)\n",
        "\n",
        "saidas = Dense(len(classes), activation=ATIVACAO_SAIDA, name='camada_saida')(camadas)\n",
        "\n",
        "modelo = Model(inputs=entradas, outputs=saidas, name=modelo_nome)\n",
        "\n",
        "modelo.compile(loss=PERDA,\n",
        "               optimizer=Adam(learning_rate=APRENDIZADO),\n",
        "               metrics=METRICAS)\n",
        "\n",
        "historico = modelo.fit(dados_treino,\n",
        "                       epochs=ITERACOES,\n",
        "                       validation_data=dados_validacao,\n",
        "                       verbose=1)"
      ],
      "metadata": {
        "id": "oYEdZE6s0F6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafico_historico_por_iteracao(historico)"
      ],
      "metadata": {
        "id": "GqS2eo02276k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades = modelo.predict(dados_validacao)\n",
        "previsoes      = tf.argmax(probabilidades, axis=1)\n",
        "avaliacoes[2]  = avaliar_modelo(rotulos_int_validacao, previsoes, classes)"
      ],
      "metadata": {
        "id": "J5lUNxJ_3Axz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes[2]"
      ],
      "metadata": {
        "id": "iRbuW8Nh3AsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos caracteres"
      ],
      "metadata": {
        "id": "QjgLcEPf3Amu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caracteres_por_texto    = [len(texto) for texto in df_treino['texto']]\n",
        "caracteres_por_texto_95 = int(np.percentile(caracteres_por_texto, 95))  # Quantidade máxima de caracteres para 95% dos textos."
      ],
      "metadata": {
        "id": "E0pxxUvmGzTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Média: {np.mean(caracteres_por_texto)}\")\n",
        "print(f\"Máximo: {np.max(caracteres_por_texto)}\")\n",
        "print(f\"95%: {caracteres_por_texto_95}\")"
      ],
      "metadata": {
        "id": "b9asU3JlEQZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(x=caracteres_por_texto, color=COR)\n",
        "\n",
        "plt.xlim(0, 300)\n",
        "\n",
        "plt.xlabel('Quantidade de caracteres')\n",
        "plt.ylabel('Quantidade de textos');"
      ],
      "metadata": {
        "id": "6EJS1vNBEQZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Listas de caracteres"
      ],
      "metadata": {
        "id": "SbBiHLhsHudf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_caracteres_treino    = [\" \".join(list(texto)) for texto in df_treino['texto']]\n",
        "lista_caracteres_validacao = [\" \".join(list(texto)) for texto in df_validacao['texto']]\n",
        "lista_caracteres_teste     = [\" \".join(list(texto)) for texto in df_teste['texto']]"
      ],
      "metadata": {
        "id": "vzjrtsvIHQ1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vetorização"
      ],
      "metadata": {
        "id": "bM0_3wobIXFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vetorizador_caracteres = TextVectorization(max_tokens=LIMITE_CARACTERES,\n",
        "                                           output_mode='int',\n",
        "                                           output_sequence_length=caracteres_por_texto_95,\n",
        "                                           name='vetorizador_caracteres')\n",
        "\n",
        "vetorizador_caracteres.adapt(lista_caracteres_treino)"
      ],
      "metadata": {
        "id": "cj6oo8JxIXFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vetorizador_caracteres.get_config()"
      ],
      "metadata": {
        "id": "CKxOJL76IXFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vocabulário"
      ],
      "metadata": {
        "id": "9y1O0XZXIXFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario_caracteres = vetorizador_caracteres.get_vocabulary()\n",
        "\n",
        "print(f\"Tamanho do vocabulário: {len(vocabulario_caracteres)}\")\n",
        "print(f\"10 caracteres mais comuns: {vocabulario_caracteres[:10]}\")\n",
        "print(f\"10 caracteres menos comuns: {vocabulario_caracteres[-10:]}\")"
      ],
      "metadata": {
        "id": "1WUV2_r5IXFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Incorporação"
      ],
      "metadata": {
        "id": "jt-5UfbPIXFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incorporador_caracteres = Embedding(input_dim=len(vocabulario_caracteres),\n",
        "                                    output_dim=LIMITE_INCORPORADOR_CARACTERES,\n",
        "                                    mask_zero=True,\n",
        "                                    input_length=caracteres_por_texto_95,\n",
        "                                    name='incorporador_caracteres')"
      ],
      "metadata": {
        "id": "Q3alwoI7IXFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorporador_caracteres.get_config()"
      ],
      "metadata": {
        "id": "1pK0YLIuIXFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Verificação"
      ],
      "metadata": {
        "id": "ly2PWk0dIXFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_aleatorio = random.choice(lista_caracteres_treino)\n",
        "\n",
        "vetorizado = vetorizador_caracteres([texto_aleatorio])\n",
        "incorporado = incorporador_caracteres(vetorizado)\n",
        "\n",
        "print(texto_aleatorio)\n",
        "print()\n",
        "print(f\"Quantidade de caracteres: {len(texto_aleatorio.split())}\")\n",
        "print(f\"Formato vetorizado: {vetorizado.shape}\")\n",
        "print(f\"Formato incorporado: {incorporado.shape}\")\n",
        "print()\n",
        "print(vetorizado)\n",
        "print()\n",
        "print(incorporado)"
      ],
      "metadata": {
        "id": "eXvchSBvIXFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Criação de datasets"
      ],
      "metadata": {
        "id": "39Aw_gWSNLRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "caracteres_treino    = Dataset.from_tensor_slices((lista_caracteres_treino, rotulos_onehot_treino))\n",
        "caracteres_validacao = Dataset.from_tensor_slices((lista_caracteres_validacao, rotulos_onehot_validacao))\n",
        "caracteres_teste     = Dataset.from_tensor_slices((lista_caracteres_teste, rotulos_onehot_teste))"
      ],
      "metadata": {
        "id": "-4akrLZ5NLRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caracteres_treino"
      ],
      "metadata": {
        "id": "D45KgBeLNLRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-buscas\n",
        "caracteres_treino    = caracteres_treino.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)\n",
        "caracteres_validacao = caracteres_validacao.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)\n",
        "caracteres_teste     = caracteres_teste.batch(LOTE_TAMANHO).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "ljbXXb6ZNLRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caracteres_treino"
      ],
      "metadata": {
        "id": "VmXYT7rcNLRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo 3: Conv1D com incorporação de caracteres"
      ],
      "metadata": {
        "id": "W9HK252ZNLRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_nome = 'modelo_3_conv1d_inc_caracteres'\n",
        "\n",
        "entradas = Input(shape=ENTRADA_FORMATO, dtype=ENTRADA_TIPO, name='camada_entrada')\n",
        "\n",
        "camadas = vetorizador_caracteres(entradas)\n",
        "camadas = incorporador_caracteres(camadas)\n",
        "\n",
        "camadas = Conv1D(filters=FILTROS,\n",
        "                 kernel_size=NUCLEO_TAMANHO,\n",
        "                 activation=ATIVACAO,\n",
        "                 padding=PREENCHIMENTO,\n",
        "                 name='camada_convulacional')(camadas)\n",
        "\n",
        "camadas = GlobalMaxPool1D(name='agrupamento_maximo_global')(camadas)\n",
        "\n",
        "saidas = Dense(len(classes), activation=ATIVACAO_SAIDA, name='camada_saida')(camadas)\n",
        "\n",
        "modelo = Model(inputs=entradas, outputs=saidas, name=modelo_nome)\n",
        "\n",
        "modelo.compile(loss=PERDA,\n",
        "               optimizer=Adam(learning_rate=APRENDIZADO),\n",
        "               metrics=METRICAS)\n",
        "\n",
        "historico = modelo.fit(caracteres_treino,\n",
        "                       epochs=ITERACOES * 2,\n",
        "                       validation_data=caracteres_validacao,\n",
        "                       verbose=1)"
      ],
      "metadata": {
        "id": "LpjBsWGHNLRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafico_historico_por_iteracao(historico)"
      ],
      "metadata": {
        "id": "-wX1nVhUNLRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilidades = modelo.predict(caracteres_validacao)\n",
        "previsoes      = tf.argmax(probabilidades, axis=1)\n",
        "avaliacoes[3]  = avaliar_modelo(rotulos_int_validacao, previsoes, classes)"
      ],
      "metadata": {
        "id": "BKp0J6XJNLRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes[3]"
      ],
      "metadata": {
        "id": "vXhFllJNNLRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo 4: Camada de incorporação híbrida"
      ],
      "metadata": {
        "id": "2Awk_cOsNThs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvZtXTH-UqR3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}